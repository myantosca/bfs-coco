txt2mpig, genmpig, bfs-coco
===========================

`txt2mpig` converts the edge-centric graph model stored in a text file to a packed binary format.

`genmpig` generates an Erdos-Renyi graph and stores the edges in the same format as `txt2mpig`.

`bfs-coco` reads an input file generated by `txt2mpig` or `genmpig` and outputs the connected
components in the graph along with some basic component statistics.

txt2mpig
--------

### Usage

`mpirun -np` <node count> `txt2mpig -- -i` <input file> `-o` <output file> `-b` <edges per output block>

`-i` <input file>  : A textual edge-centric graph model representation with one edge per line.
                     Edge format: "[0-9]+ [0-9]+\n" (2 unsigned integers separated by whitespace)
`-o` <output file> : A binary edge-centric graph model representation with endpoint labels packed in tandem.
                     Edge format: <u|v> (4 bytes/label, 8 bytes/edge)
					 Default: `./graph.ecg`
`-b` <edges/block> : Output block buffering size in edges.
	                 Default: 1

### Notes
`txt2mpig` was designed to work with edge-centric text files available from the SNAP database
(https://snap.stanford.edu/data/). It reads the file in line by line, and discards lines that do not match
the expected format exactly (as understood by sscanf). The program does not deduplicate the input.

The edges are read at the root node until the read buffer is full or EOF is reached.
When this occurs, a portion of the read buffer is scattered to each participating machine which
then makes an independent write to a contiguous, non-overlapping area in the output file.

When the writes are complete, the absolute write offset is updated, and the read buffer offset is reset.
The transfer of data continues until the input file is exhausted. In the case where the read buffer
is not evenly divisible by the number of participating machines, the remainder of that division
is distributed to the lower ranked nodes. This remainder is accounted for in the per-machine
offset calculations so as to preserve the integrity of the output.

The default argument for the block buffering size is not a recommendation by any stretch.
Users should determine the best value for the particular use case. Best practice would seem to
be a multiple of the operating system block size divided by 8 bytes/edge.

genmpig
-------

### Usage

`mpirun -np` <node count> `genmpig -- -p` <edge probability> `-n` <population size> `-b` <edges/block>
                                      `-o` <output file> [`-m`]

`-o` <output file> : A binary edge-centric graph model representation with endpoint labels packed in tandem.
                     Edge format: <u|v> (4 bytes/label, 8 bytes/edge)
					 Default: `./graph.ecg`
`-b` <edges/block> : Output block buffering size in edges.
	                 Default: 1
`-p` <edge probability> : The independent probability of existence for any given edge in the graph.
                          The argument should be a double-precision value in the range [0,1].
                          Default: 0
`-n` <population size>  : The population size of the graph in terms of vertices.
	                      The argument should be a 32-bit unsigned integer.
                          Default: 1
`-m` : A switch to use Monte-Carlo edge selection instead of the naive Las Vegas edge selection.

### Notes
`gen2mpig` generates edge-centric graph model files in a packed binary format. A couple parameters are
the same or similar to those used by `txt2mpig`, but the write strategy is quite different since there
is an element of randomness introduced. In order to maximize the speed with which edges are generated,
each machine participates on behalf of a single node and its incident edges. To avoid duplicating effort,
each node under consideration only tests edges to nodes with higher labels since the edge to node
with lower label would have been generated (or not) during the consideration of the lower label node.

Additionally, there is no predictor that can calculate file offsets _a priori_ since each machine might
end up with an imbalanced load. Instead, a task-based parallel approach is employed and all machines
use a shared file pointer to accomplish writes via the MP/IO interface.

The `-p` and `-n` arguments are fairly self-explanatory in the default edge-selection context.
Under this scenario, each edge is tested by a Bernoulli sampling against a distribution with success
probability as given. This approach, while probabilistically sound, does not scale particularly well.
The combinatorial explosion of predicates becomes almost insurmountable.

To this end, the `-m` option is provided. Instead of doing individual Bernoulli tests, a random variable
with a binomial distribution is sampled to find the _number_ of incident edges against a given node.
The specific edges are taken from a random sampling of a uniform distribution of the graph's node labels.
Hence, whereas the naive selection scheme could be termed a Las Vegas randomized algorithm, this new scheme
falls under the Monte Carlo family of randomized algorithms.

The Monte Carlo edge selection scheme cannot guarantee that the random sampling of node labels will not
produce duplicate edges. For instance, if the edge probability is given as 1, the scheme may not generate
a complete graph. The naive scheme, on the other hand, will generate a complete graph.

Whether this massive increase in generation speed justifies the loss of probabilistic correctness remains
to be tested under experiment.
